{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55afec78-493f-4288-8ab5-f5ac9cefda16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pandas import DataFrame\n",
    "from json import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30f76cd9-e9e8-4936-a297-6a4d36cac798",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/@PW-Foundation/videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d3b8f0c-3ecd-48a3-b25c-14250a393bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.youtube.com/@PW-Foundation/videos'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7f8e835-9be9-4d7d-8a2f-e0728e866716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# Get the html by get method\n",
    "r = requests.get(url)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1051720-1dc5-4821-b948-416a6882e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create BeautifulSoup object\n",
    "youtube_html = BeautifulSoup(r.text , 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "155e1346-4592-439e-ab44-fa1bff54023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_box = youtube_html.find_all('script')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fcd950e-9e3c-42a9-9d0e-da2fa6f4e12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74478481-306b-4c92-a53f-a68fe7f87853",
   "metadata": {},
   "source": [
    "So far, this code imports necessary modules for web scraping, sends an HTTP GET request to a YouTube channel URL, creates a BeautifulSoup object from the HTML code of the web page, and finds all the script tags in the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69eee7c8-c605-4b46-991f-c9577ce6db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def script_to_json(tags: list) -> dict:\n",
    "    for tag in reversed(tags):\n",
    "        text: str = tag.text\n",
    "        if 'ytInitialData = {\"responseContext\"' in text:\n",
    "            return loads(text[20:-1])\n",
    "        \n",
    "    raise ValueError('Required script tag is not found in the given tags ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130b280-4493-4050-a6f4-ce019e9db256",
   "metadata": {},
   "source": [
    "This code defines a function script_to_json() that converts a script tag to a JSON object.\n",
    "\n",
    "The function takes a list of script tags as input and searches for the tag that contains the JSON data that we are interested in. It does this by iterating over the list of tags in reverse order (starting from the end of the list), and searching for the ytInitialData JSON object in the text attribute of each tag.\n",
    "\n",
    "If the required ytInitialData JSON object is found, the function extracts the JSON string from the text attribute of the tag (excluding the first 20 and last 1 characters, which contain some unwanted characters), and uses the loads() method from the json module to convert the string to a Python dictionary.\n",
    "\n",
    "If the required ytInitialData JSON object is not found in any of the tags, the function raises a ValueError.\n",
    "\n",
    "The resulting dictionary contains the data that we are interested in, which can be used for further analysis or manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e957356b-62af-4612-800b-007006a54bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_data = script_to_json(big_box)\n",
    "\n",
    "#Return data from videos\n",
    "def get_contents_dict(data):\n",
    "    return data['contents']['twoColumnBrowseResultsRenderer']['tabs'][1]['tabRenderer']['content']['richGridRenderer']['contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9696a843-4d0e-418a-a490-67495994c7d7",
   "metadata": {},
   "source": [
    "This code defines a function get_contents_dict() that extracts the contents dictionary from the ytInitialData JSON object.\n",
    "\n",
    "The function takes the ytInitialData dictionary as input and returns the contents dictionary that contains the data for the videos on the channel.\n",
    "\n",
    "The contents dictionary can be found by navigating through the various keys in the ytInitialData dictionary. In this case, we can find it by following this path:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f263727d-c0ef-464d-bdfb-bcf8b9305dfc",
   "metadata": {},
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b4cfeed-ca6d-47a8-89b3-ffb984802b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=jXAb1evxaJc',\n",
       " 'https://www.youtube.com/watch?v=2dn7XMxRtPE',\n",
       " 'https://www.youtube.com/watch?v=Fks4dVnTb5M',\n",
       " 'https://www.youtube.com/watch?v=nIuGXeISbSo',\n",
       " 'https://www.youtube.com/watch?v=p9pqo970kjw']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_videoUrl(data:dict, n: int = 5):\n",
    "    contents = get_contents_dict(youtube_data)\n",
    "\n",
    "    if n > 30:\n",
    "        raise ValueError('Max Limit is 30.')\n",
    "\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append('https://www.youtube.com/watch?v=' +\n",
    "                        contents[i]['richItemRenderer']['content']['videoRenderer']['videoId'])\n",
    "    return result\n",
    "\n",
    "get_videoUrl(youtube_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584ea25f-a1de-4239-95e7-5974dcf385cb",
   "metadata": {},
   "source": [
    "This code defines a function get_videoUrl() that extracts the URLs of the first n videos on the channel.\n",
    "\n",
    "The function takes the ytInitialData dictionary as input and an optional parameter n that specifies the number of videos to retrieve (default value is 5). The function first extracts the contents dictionary using the get_contents_dict() function, and then iterates over the first n items in the contents list.\n",
    "\n",
    "For each item, the function extracts the videoId from the videoRenderer dictionary and concatenates it with the YouTube video URL to create the full URL for the video. The resulting list result contains the URLs of the first n videos on the channel.\n",
    "\n",
    "Note that the function raises a ValueError if the value of n is greater than 30, which is the maximum number of videos that can be retrieved from the YouTube API in a single request. This limit is enforced to prevent excessive usage of the API, which could result in rate limiting or other errors."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae381b60-faef-4788-b935-8bc83398df8e",
   "metadata": {},
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f2175b9-7035-4784-9c22-0ce7b035af24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://i.ytimg.com/vi/jXAb1evxaJc/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLDmeiri9cimEVHPiAh5ootidgIzIg',\n",
       " 'https://i.ytimg.com/vi/2dn7XMxRtPE/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLCNuCKbYYT7Bqo7b2xVfh27z3YKMw',\n",
       " 'https://i.ytimg.com/vi/Fks4dVnTb5M/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLCHXf5XebQJcUioL-AX9g1ZXcizVQ',\n",
       " 'https://i.ytimg.com/vi/nIuGXeISbSo/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLDnazWdDQJGyaWrFBfL4fojeCtPFg',\n",
       " 'https://i.ytimg.com/vi/p9pqo970kjw/hqdefault.jpg?sqp=-oaymwEjCNACELwBSFryq4qpAxUIARUAAAAAGAElAADIQj0AgKJDeAE=&rs=AOn4CLAOxBxNmM_rbpVXQ9jFGTcaP2Dalg']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_thumbnails(data:dict , n:int = 5):\n",
    "    contents =get_contents_dict(youtube_data)\n",
    "    \n",
    "    if n>30:\n",
    "        raise ValueError('Max Limit is 30')\n",
    "        \n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(contents[i]['richItemRenderer']['content']['videoRenderer']['thumbnail']['thumbnails'][-1]['url'])\n",
    "        \n",
    "    return result\n",
    "get_thumbnails(youtube_data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489d2df-92bf-47a7-8c61-9c6737df6808",
   "metadata": {},
   "source": [
    "This code defines a function get_thumbnails() that extracts the URLs of the thumbnail images for the first n videos on the channel.\n",
    "\n",
    "The function takes the ytInitialData dictionary as input and an optional parameter n that specifies the number of thumbnails to retrieve (default value is 5). The function first extracts the contents dictionary using the get_contents_dict() function, and then iterates over the first n items in the contents list.\n",
    "\n",
    "For each item, the function extracts the URL of the highest resolution thumbnail image by selecting the last item in the thumbnails list of the thumbnail dictionary.\n",
    "\n",
    "The resulting list result contains the URLs of the thumbnail images for the first n videos on the channel. These URLs can be used to download and display the thumbnail images for each video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c770c23-02cc-495a-a907-62d283a663b7",
   "metadata": {},
   "source": [
    "Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77908e3d-9772-4aba-9805-921c0309e3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Big Announcement for Gulf Region Aspirants ðŸ”¥| Physics Wallah Gulf Channel TrailerðŸš€',\n",
       " 'Arjuna JEE v/s Arjuna NEET ðŸ- Class 11th Faculties ka Cricket Match ðŸ”¥',\n",
       " 'How to Study Zoology in Class 11th? Ab Saare Doubts Solve Honge !! ðŸ”¥',\n",
       " 'BIGGEST OFFER For Class - 8th ,9th & 10th Students ðŸ¤© || Grab This Opportunity Now ðŸ”¥',\n",
       " 'Launching PW à¤ªà¥à¤°à¤¯à¥‹à¤—à¤¶à¤¾à¤²à¤¾ 2.0 ðŸ”¥ || The Unbeatable is Loading...']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_title(data:dict , n:int=5):\n",
    "    contents=get_contents_dict(youtube_data)\n",
    "    \n",
    "    if n>30:\n",
    "        raise ValueError('Max Limit is 30')\n",
    "        \n",
    "    result=[]\n",
    "    for i in range(n):\n",
    "        result.append(contents[i]['richItemRenderer']['content']['videoRenderer']['title']['runs'][-1]['text'])\n",
    "        \n",
    "    return result\n",
    "get_title(youtube_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf32063-3a93-419e-8d7c-0029f35467a5",
   "metadata": {},
   "source": [
    "This code defines a function get_title() that extracts the titles of the first n videos on the channel.\n",
    "\n",
    "The function takes the ytInitialData dictionary as input and an optional parameter n that specifies the number of titles to retrieve (default value is 5). The function first extracts the contents dictionary using the get_contents_dict() function, and then iterates over the first n items in the contents list.\n",
    "\n",
    "For each item, the function extracts the title of the video by selecting the last item in the runs list of the title dictionary.\n",
    "\n",
    "The resulting list result contains the titles of the first n videos on the channel. These titles can be used to identify each video and to display the titles in a list or table."
   ]
  },
  {
   "cell_type": "raw",
   "id": "494f8769-f1ea-46ab-b846-19d248631dd5",
   "metadata": {},
   "source": [
    "Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bf6f19e-99c2-46f0-9bbe-8358853f8a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52557, 248083, 8987, 34842, 30439]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_views(data: dict , n :int = 5):\n",
    "    contents = get_contents_dict(youtube_data)\n",
    "    \n",
    "    if n > 30:\n",
    "        raise ValueError('MAx Limit is 30')\n",
    "        \n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(int(contents[i]['richItemRenderer']['content']['videoRenderer']['viewCountText']['simpleText']\n",
    "                      [:-6].replace(',' , '')))\n",
    "        \n",
    "    return result\n",
    "get_views(youtube_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b4c975-9d7d-484c-b274-475a26fbd6bc",
   "metadata": {},
   "source": [
    "This code defines a function get_views() that extracts the view counts of the first n videos on the channel.\n",
    "\n",
    "The function takes the ytInitialData dictionary as input and an optional parameter n that specifies the number of view counts to retrieve (default value is 5). The function first extracts the contents dictionary using the get_contents_dict() function, and then iterates over the first n items in the contents list.\n",
    "\n",
    "For each item, the function extracts the view count of the video by selecting the simpleText value of the viewCountText dictionary. The view count is then converted to an integer by removing the last six characters (which represent \" views\") and any commas.\n",
    "\n",
    "The resulting list result contains the view counts of the first n videos on the channel. These view counts can be used to measure the popularity of each video and to display the view counts in a list or table."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b4d04b5-1b13-478c-a801-3956338dec3e",
   "metadata": {},
   "source": [
    "Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a168d482-3bb5-4fdd-80a5-c95d41ffc24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5 days ago', '7 days ago', '2 weeks ago', '2 weeks ago', '2 weeks ago']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_time_of_post(data: dict , n : int=5):\n",
    "    contents = get_contents_dict(youtube_data)\n",
    "    \n",
    "    if n > 30:\n",
    "        raise ValueError('Max Limit is 30')\n",
    "            \n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(contents[i]['richItemRenderer']['content']['videoRenderer']['publishedTimeText']['simpleText'])\n",
    "        \n",
    "    return result\n",
    "get_time_of_post(youtube_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725cd21-128b-4b08-a1f3-138db232b971",
   "metadata": {},
   "source": [
    "This code defines a function get_time_of_posting() that extracts the publication dates of the first n videos on the channel.\n",
    "\n",
    "The function takes the ytInitialData dictionary as input and an optional parameter n that specifies the number of publication dates to retrieve (default value is 5). The function first extracts the contents dictionary using the get_contents_dict() function, and then iterates over the first n items in the contents list.\n",
    "\n",
    "For each item, the function extracts the publication date of the video by selecting the simpleText value of the publishedTimeText dictionary.\n",
    "\n",
    "The resulting list result contains the publication dates of the first n videos on the channel. These dates can be used to determine when each video was published and to display the publication dates in a list or table."
   ]
  },
  {
   "cell_type": "raw",
   "id": "983c90dd-37e1-4dde-a70a-637a0c04a041",
   "metadata": {},
   "source": [
    "Note: Save all the data scraped in the above questions in a CSV file."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a59a2e50-b93c-413a-a5ad-36a8cd866e76",
   "metadata": {},
   "source": [
    "Save data in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5e1b33d-1532-444e-90ff-34f3b4cd7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_video_detials(data:dict , n:int):\n",
    "    thumbnails = get_thumbnails(data , n)\n",
    "    time_of_post = get_time_of_post(data , n)\n",
    "    titles = get_title(data, n)\n",
    "    video_urls = get_videoUrl(data , n)\n",
    "    viwes = get_views(data , n)\n",
    "    \n",
    "    main_data = list(zip(video_urls,titles,time_of_post,viwes,thumbnails))\n",
    "    \n",
    "    df = DataFrame.from_dict(main_data)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            0:'video_urls',\n",
    "            1:'titles',\n",
    "            2:'thumbnails_url',\n",
    "            3:'views_post',\n",
    "            4:'time_of_posting'\n",
    "        }, inplace = True)\n",
    "    \n",
    "    return df\n",
    "channel_data = get_channel_video_detials(data,30)\n",
    "channel_data.to_csv('Abhi-pw_foundation', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fc040830-a802-4899-8e9a-21149e55c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_video_details(data: dict, n: int):\n",
    "    thumbnails = get_thumbnails(data, n)\n",
    "    time_of_posting = get_time_of_post(data, n)\n",
    "    titles = get_title(data, n)\n",
    "    video_urls = get_videoUrl(data, n)\n",
    "    views = get_views(data , n)\n",
    "    \n",
    "    main_data = list(zip(video_urls, titles, thumbnails, time_of_posting , views))\n",
    "    \n",
    "    df = DataFrame.from_dict(main_data)\n",
    "    df.rename(\n",
    "        columns={\n",
    "            0: 'video_urls',\n",
    "            1: 'title',\n",
    "            2: 'thumbnail_url',\n",
    "            3: 'time_of_posting',\n",
    "            4: 'views'\n",
    "        }, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "channel_data = get_channel_video_details(data, 10)\n",
    "channel_data.to_csv('bhi-PW-Foundation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a96ec-e3c0-48f2-a2a7-74720bb9a5ee",
   "metadata": {},
   "source": [
    "This code defines a function get_channel_video_details() that extracts the video details of the first n videos on the channel.\n",
    "\n",
    "The function takes the ytInitialData dictionary as input and an integer n that specifies the number of videos to retrieve. The function calls the get_thumbnails(), get_time_of_posting(), get_title(), and get_videoUrl() functions to extract the thumbnail URLs, publication dates, titles, and video URLs of the first n videos on the channel. It then zips these lists together into a single list of tuples called main_data.\n",
    "\n",
    "The function then creates a Pandas DataFrame from main_data and renames the columns to video_urls, title, thumbnail_url, and time_of_posting. Finally, the function returns the DataFrame.\n",
    "\n",
    "The resulting DataFrame channel_data contains the video details of the first n videos on the channel, including the video URLs, titles, thumbnail URLs, and publication dates. The DataFrame is saved to a CSV file called PW-Foundation.csv with the to_csv() method.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2980f8fe-95be-4cbb-92fc-28d0aafd5d7f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
